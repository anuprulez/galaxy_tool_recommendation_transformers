{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ffbe4a-b59d-40e1-a90c-6c67be989a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparision of recommendations by Transformer and RNN\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Embedding, SpatialDropout1D, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "\n",
    "\n",
    "fig_size = (15, 15)\n",
    "font = {'family': 'serif', 'size': 8}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "test_batches = 1\n",
    "n_topk = 1\n",
    "max_seq_len = 25\n",
    "\n",
    "embed_dim = 128 # Embedding size for each token d_model\n",
    "num_heads = 4 # Number of attention heads\n",
    "ff_dim = 128 # Hidden layer size in feed forward network inside transformer # dff\n",
    "dropout = 0.1\n",
    "seq_len = 25\n",
    "\n",
    "# Set to true only when RNN model should be executed\n",
    "predict_rnn = False\n",
    "\n",
    "if predict_rnn is True:\n",
    "    base_path = \"../models/rnn/\"\n",
    "else:\n",
    "    base_path = \"../models/transformer/\"\n",
    "\n",
    "model_number = 40000\n",
    "model_path = base_path + \"saved_model/\" + str(model_number) + \"/tf_model/\"\n",
    "model_path_h5 = base_path + \"saved_model/\" + str(model_number) + \"/tf_model_h5/\"\n",
    "\n",
    "\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=rate)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output, attention_scores = self.att(inputs, inputs, inputs, return_attention_scores=True, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output), attention_scores\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        file_content = json.loads(json_file.read())\n",
    "    return file_content\n",
    "\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Write a file\n",
    "    \"\"\"\n",
    "    remove_file(file_path)\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json_file.write(json.dumps(content))\n",
    "\n",
    "def create_rnn_model(seq_len, vocab_size):\n",
    "\n",
    "    seq_inputs = tf.keras.Input(batch_shape=(None, seq_len))\n",
    "\n",
    "    gen_embedding = tf.keras.layers.Embedding(vocab_size, embed_dim, mask_zero=True)\n",
    "    in_gru = tf.keras.layers.GRU(ff_dim, return_sequences=True, return_state=False)\n",
    "    out_gru = tf.keras.layers.GRU(ff_dim, return_sequences=False, return_state=True)\n",
    "    enc_fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid', kernel_regularizer=\"l2\")\n",
    "    embed = gen_embedding(seq_inputs)\n",
    "    embed = tf.keras.layers.Dropout(dropout)(embed)\n",
    "    gru_output = in_gru(embed)\n",
    "    gru_output = tf.keras.layers.Dropout(dropout)(gru_output)\n",
    "    gru_output, hidden_state = out_gru(gru_output)\n",
    "    gru_output = tf.keras.layers.Dropout(dropout)(gru_output)\n",
    "    fc_output = enc_fc(gru_output)\n",
    "    return Model(inputs=[seq_inputs], outputs=[fc_output])\n",
    "\n",
    "\n",
    "def create_transformer_model(maxlen, vocab_size):\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x, weights = transformer_block(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    outputs = Dense(vocab_size, activation=\"sigmoid\")(x)\n",
    "    return Model(inputs=inputs, outputs=[x, outputs, weights])\n",
    "\n",
    "\n",
    "def get_u_tr_labels(y_tr):\n",
    "    labels = list()\n",
    "    labels_pos_dict = dict()\n",
    "    for i, item in enumerate(y_tr):\n",
    "        label_pos = np.where(item > 0)[0]\n",
    "        labels.extend(label_pos)\n",
    "        for label in label_pos:\n",
    "            if label not in labels_pos_dict:\n",
    "                labels_pos_dict[label] = list()\n",
    "            labels_pos_dict[label].append(i)\n",
    "\n",
    "    u_labels = list(set(labels))\n",
    "    \n",
    "    for item in labels_pos_dict:\n",
    "        labels_pos_dict[item] = list(set(labels_pos_dict[item]))\n",
    "    return u_labels, labels_pos_dict\n",
    "\n",
    "\n",
    "def sample_balanced_tr_y(x_seqs, y_labels, ulabels_tr_y_dict):\n",
    "    batch_y_tools = list(ulabels_tr_y_dict.keys())\n",
    "    random.shuffle(batch_y_tools)\n",
    "    label_tools = list()\n",
    "    rand_batch_indices = list()\n",
    "\n",
    "    for l_tool in batch_y_tools:\n",
    "        seq_indices = ulabels_tr_y_dict[l_tool]\n",
    "        random.shuffle(seq_indices)\n",
    "        \n",
    "        if seq_indices[0] not in rand_batch_indices:\n",
    "            rand_batch_indices.append(seq_indices[0])\n",
    "            label_tools.append(l_tool)\n",
    "        if len(rand_batch_indices) == batch_size:\n",
    "            break\n",
    "    \n",
    "    x_batch_train = x_seqs[rand_batch_indices]\n",
    "    y_batch_train = y_labels[rand_batch_indices]\n",
    "\n",
    "    unrolled_x = tf.convert_to_tensor(x_batch_train, dtype=tf.int64)\n",
    "    unrolled_y = tf.convert_to_tensor(y_batch_train, dtype=tf.int64)\n",
    "    return unrolled_x, unrolled_y, label_tools, rand_batch_indices\n",
    "\n",
    "\n",
    "def verify_tool_in_tr(r_dict):\n",
    "    all_sel_tool_ids = read_file(base_path + \"data/all_sel_tool_ids.txt\").split(\",\")\n",
    "\n",
    "    freq_dict = dict()\n",
    "    freq_dict_names = dict()\n",
    "\n",
    "    for tool_id in all_sel_tool_ids:\n",
    "        if tool_id not in freq_dict:\n",
    "            freq_dict[tool_id] = 0\n",
    "\n",
    "        if tool_id not in freq_dict_names:\n",
    "            freq_dict_names[r_dict[str(int(tool_id))]] = 0\n",
    "\n",
    "        freq_dict[tool_id] += 1\n",
    "        freq_dict_names[r_dict[str(int(tool_id))]] += 1\n",
    "\n",
    "    s_freq = dict(sorted(freq_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    s_freq_names = dict(sorted(freq_dict_names.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "    write_file(base_path + \"data/s_freq_names.txt\", s_freq_names)\n",
    "    write_file(base_path + \"data/s_freq.txt\", s_freq)\n",
    "\n",
    "    return s_freq\n",
    "\n",
    "\n",
    "def read_h5_model():\n",
    "    print(model_path_h5)\n",
    "    h5_path = model_path_h5 + \"model.h5\"\n",
    "    model_h5 = h5py.File(h5_path, 'r')\n",
    "\n",
    "    r_dict = json.loads(model_h5[\"reverse_dict\"][()].decode(\"utf-8\"))\n",
    "    m_load_s_time = time.time()\n",
    "    tf_loaded_model = create_transformer_model(seq_len, len(r_dict) + 1)\n",
    "    tf_loaded_model.load_weights(h5_path)\n",
    "    m_load_e_time = time.time()\n",
    "    model_loading_time = m_load_e_time - m_load_s_time\n",
    "\n",
    "    f_dict = dict((v, k) for k, v in r_dict.items())\n",
    "    c_weights = json.loads(model_h5[\"class_weights\"][()].decode(\"utf-8\"))\n",
    "    c_tools = json.loads(model_h5[\"compatible_tools\"][()].decode(\"utf-8\"))\n",
    "    s_conn = json.loads(model_h5[\"standard_connections\"][()].decode(\"utf-8\"))\n",
    "\n",
    "    model_h5.close()\n",
    "\n",
    "    return tf_loaded_model, f_dict, r_dict, c_weights, c_tools, s_conn, model_loading_time\n",
    "\n",
    "\n",
    "def read_model():\n",
    "    m_load_s_time = time.time()\n",
    "    tf_loaded_model = tf.saved_model.load(model_path)\n",
    "    m_load_e_time = time.time()\n",
    "    m_l_time = m_load_e_time - m_load_s_time\n",
    "    r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "    f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "    c_weights = read_file(base_path + \"data/class_weights.txt\")\n",
    "    c_tools = read_file(base_path + \"data/compatible_tools.txt\")\n",
    "    s_conn = read_file(base_path + \"data/published_connections.txt\")\n",
    "\n",
    "    return tf_loaded_model, f_dict, r_dict, c_weights, c_tools, s_conn, m_l_time\n",
    "\n",
    "\n",
    "def recommend_tools():\n",
    " \n",
    "    path_test_data = base_path + \"saved_data/test.h5\"\n",
    "\n",
    "    file_obj = h5py.File(path_test_data, 'r')\n",
    "\n",
    "    test_input = np.array(file_obj[\"input\"])\n",
    "    test_target = np.array(file_obj[\"target\"])\n",
    "\n",
    "    print(test_input.shape, test_target.shape)\n",
    "\n",
    "    if predict_rnn is True:\n",
    "        print(model_path)\n",
    "        m_load_s_time = time.time()\n",
    "        tf_loaded_model = tf.saved_model.load(model_path)\n",
    "        m_load_e_time = time.time()\n",
    "        model_loading_time = m_load_e_time - m_load_s_time\n",
    "        r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "        f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "        class_weights = read_file(base_path + \"data/class_weights.txt\")\n",
    "        compatible_tools = read_file(base_path + \"data/compatible_tools.txt\")\n",
    "        published_connections = read_file(base_path + \"data/published_connections.txt\")\n",
    "    else:\n",
    "        tf_loaded_model, f_dict, r_dict, class_weights, compatible_tools, published_connections, model_loading_time = read_h5_model()\n",
    "\n",
    "    c_weights = list(class_weights.values())\n",
    "\n",
    "    c_weights = tf.convert_to_tensor(c_weights, dtype=tf.float32)\n",
    "\n",
    "    u_te_y_labels, u_te_y_labels_dict = get_u_tr_labels(test_target)\n",
    "\n",
    "    precision = list()\n",
    "    pub_prec_list = list()\n",
    "    error_label_tools = list()\n",
    "    batch_pred_time = list()\n",
    "    for j in range(test_batches):\n",
    "\n",
    "        te_x_batch, y_train_batch, selected_label_tools, bat_ind = sample_balanced_tr_y(test_input, test_target, u_te_y_labels_dict)\n",
    "\n",
    "        te_x_batch = tf.cast(te_x_batch, dtype=tf.float32, name=\"input_2\")\n",
    "        \n",
    "        pred_s_time = time.time()\n",
    "        \n",
    "        if predict_rnn is True:\n",
    "            te_prediction = tf_loaded_model(te_x_batch, training=False)\n",
    "        else:\n",
    "            embed, te_prediction, att_weights = tf_loaded_model(te_x_batch, training=False)\n",
    "           \n",
    "        pred_e_time = time.time()\n",
    "        diff_time = (pred_e_time - pred_s_time) / float(batch_size)\n",
    "        batch_pred_time.append(diff_time)\n",
    "        \n",
    "        for i, (inp, tar) in enumerate(zip(te_x_batch, y_train_batch)):\n",
    "\n",
    "            t_ip = te_x_batch[i]\n",
    "            tar = y_train_batch[i]\n",
    "            prediction = te_prediction[i]\n",
    "            if len(np.where(inp > 0)[0]) <= max_seq_len:\n",
    "                real_prediction = np.where(tar > 0)[0]\n",
    "                target_pos = real_prediction\n",
    "\n",
    "                prediction_wts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "                n_topk = len(target_pos)\n",
    "                top_k = tf.math.top_k(prediction, k=n_topk, sorted=True)\n",
    "                top_k_wts = tf.math.top_k(prediction_wts, k=n_topk, sorted=True)\n",
    "\n",
    "                t_ip = t_ip.numpy()\n",
    "                label_pos = np.where(t_ip > 0)[0]\n",
    "                \n",
    "                one_target_pos = target_pos[np.random.randint(len(target_pos))]\n",
    "                \n",
    "                i_names = \",\".join([r_dict[str(int(item))] for item in t_ip[label_pos]  if item not in [0, \"0\"]])\n",
    "                t_names = \",\".join([r_dict[str(int(item))] for item in target_pos  if item not in [0, \"0\"]])\n",
    "\n",
    "                last_i_tool = [r_dict[str(int(item))] for item in t_ip[label_pos]][-1]\n",
    "\n",
    "                true_tools = [r_dict[str(int(item))] for item in target_pos]\n",
    "\n",
    "                pred_tools = [r_dict[str(int(item))] for item in top_k.indices.numpy()  if item not in [0, \"0\"]]\n",
    "                pred_tools_wts = [r_dict[str(int(item))] for item in top_k_wts.indices.numpy()  if item not in [0, \"0\"]]\n",
    "\n",
    "                intersection = list(set(true_tools).intersection(set(pred_tools)))\n",
    "\n",
    "                pub_prec = 0.0\n",
    "                pub_prec_wt = 0.0\n",
    "\n",
    "                if last_i_tool in published_connections:\n",
    "                    true_pub_conn = published_connections[last_i_tool]\n",
    "\n",
    "                    if len(pred_tools) > 0:\n",
    "                        intersection_pub = list(set(true_pub_conn).intersection(set(pred_tools)))\n",
    "                        intersection_pub_wt = list(set(true_pub_conn).intersection(set(pred_tools_wts)))\n",
    "                        pub_prec = float(len(intersection_pub)) / len(pred_tools)\n",
    "                        pub_prec_list.append(pub_prec)\n",
    "                        pub_prec_wt = float(len(intersection_pub_wt)) / len(pred_tools)\n",
    "                    else:\n",
    "                        pub_prec = False\n",
    "                        pub_prec_wt = False\n",
    "\n",
    "                if len(pred_tools) > 0:\n",
    "                    pred_precision = float(len(intersection)) / len(pred_tools)\n",
    "                    precision.append(pred_precision)\n",
    "\n",
    "                if pred_precision < 2.0:\n",
    "            \n",
    "                    print(\"Test batch {}, Tool sequence: {}\".format(j+1, [r_dict[str(int(item))] for item in t_ip[label_pos]]))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, True tools: {}\".format(j+1, true_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools: {}\".format(j+1, n_topk, pred_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools with weights: {}\".format(j+1, n_topk, pred_tools_wts))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Precision: {}\".format(j+1, pred_precision)) \n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision: {}\".format(j+1, pub_prec))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision with weights: {}\".format(j+1, pub_prec_wt))\n",
    "                    print()\n",
    "                    print(\"Time taken to predict tools: {} seconds\".format(diff_time))\n",
    "                    print(\"=========================\")\n",
    "                print(\"--------------------------\")\n",
    "                # should be uncommented to plot attention scores while executing Transformer. \n",
    "                #generated_attention(att_weights[i], i_names, f_dict, r_dict)\n",
    "                print(\"Batch {} prediction finished ...\".format(j+1))\n",
    "\n",
    "    te_lowest_t_ids = read_file(base_path + \"data/te_lowest_t_ids.txt\")\n",
    "    lowest_t_ids = [int(item) for item in te_lowest_t_ids.split(\",\")]\n",
    "    lowest_t_ids = lowest_t_ids[:1]\n",
    "    \n",
    "    low_te_data = test_input[lowest_t_ids]\n",
    "    low_te_labels = test_target[lowest_t_ids]\n",
    "    low_te_data = tf.cast(low_te_data, dtype=tf.float32)\n",
    "    low_topk = 20\n",
    "    low_te_precision = list()\n",
    "    low_te_pred_time = list()\n",
    "\n",
    "    pred_s_time = time.time()\n",
    "    if predict_rnn is True:\n",
    "        bat_low_prediction = tf_loaded_model(low_te_data, training=False)\n",
    "    else:\n",
    "        bat_embed_low, bat_low_prediction, att_weights = tf_loaded_model(low_te_data, training=False)\n",
    "    pred_e_time = time.time()\n",
    "    low_diff_pred_t = (pred_e_time - pred_s_time) / float(len(lowest_t_ids))\n",
    "    low_te_pred_time.append(low_diff_pred_t)\n",
    "    print(\"Time taken to predict tools: {} seconds\".format(low_diff_pred_t))\n",
    "\n",
    "    for i, (low_inp, low_tar) in enumerate(zip(low_te_data, low_te_labels)):\n",
    "\n",
    "        low_prediction = bat_low_prediction[i]\n",
    "        low_tar = low_te_labels[i]\n",
    "        low_label_pos = np.where(low_tar > 0)[0]\n",
    "\n",
    "        low_topk = len(low_label_pos)\n",
    "        low_topk_pred = tf.math.top_k(low_prediction, k=low_topk, sorted=True)\n",
    "        low_topk_pred = low_topk_pred.indices.numpy()\n",
    "        \n",
    "        low_label_pos_tools = [r_dict[str(int(item))] for item in low_label_pos if item not in [0, \"0\"]]\n",
    "        low_pred_label_pos_tools = [r_dict[str(int(item))] for item in low_topk_pred if item not in [0, \"0\"]]\n",
    "\n",
    "        low_intersection = list(set(low_label_pos_tools).intersection(set(low_pred_label_pos_tools)))\n",
    "        low_pred_precision = float(len(low_intersection)) / len(low_label_pos)\n",
    "        low_te_precision.append(low_pred_precision)\n",
    "\n",
    "        low_inp_pos = np.where(low_inp > 0)[0]\n",
    "        low_inp = low_inp.numpy()\n",
    "        print(low_inp, low_inp_pos)\n",
    "        print(\"{}, Low: test tool sequence: {}\".format(i, [r_dict[str(int(item))] for item in low_inp[low_inp_pos]]))\n",
    "        print()\n",
    "        print(\"{},Low: True labels: {}\".format(i, low_label_pos_tools))\n",
    "        print()\n",
    "        print(\"{},Low: Predicted labels: {}, Precision: {}\".format(i, low_pred_label_pos_tools, low_pred_precision))\n",
    "       \n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "\n",
    "    if test_batches > 0:\n",
    "        print(\"Batch Precision@{}: {}\".format(n_topk, np.mean(precision)))\n",
    "        print(\"Batch Published Precision@{}: {}\".format(n_topk, np.mean(pub_prec_list)))\n",
    "        print(\"Batch Trained model loading time: {} seconds\".format(model_loading_time))\n",
    "        print(\"Batch average seq pred time: {} seconds\".format(np.mean(batch_pred_time)))\n",
    "        print(\"Batch total model loading and pred time: {} seconds\".format(model_loading_time + np.mean(batch_pred_time)))\n",
    "        print()\n",
    "        \n",
    "    print(\"----------------------------\")\n",
    "    print()\n",
    "    print(\"Predicting for individual sequences...\")\n",
    "    print()\n",
    "    print(\"Predicting for individual tools or sequences\")\n",
    "    n_topk_ind = 20\n",
    "    t_ip = np.zeros((1, 25))\n",
    "\n",
    "    t_ip[0, 0] = int(f_dict[\"bowtie2\"])\n",
    "    t_ip[0, 1] = int(f_dict[\"hicexplorer_hicbuildmatrix\"])\n",
    "    t_ip[0, 2] = int(f_dict[\"hicexplorer_chicqualitycontrol\"])\n",
    "    t_ip[0, 3] = int(f_dict[\"hicexplorer_chicviewpointbackgroundmodel\"])\n",
    "    t_ip[0, 4] = int(f_dict[\"hicexplorer_chicviewpoint\"])\n",
    "    \n",
    "    last_tool_name = \"hicexplorer_chicviewpoint\"\n",
    "    \n",
    "    t_ip = tf.convert_to_tensor(t_ip, dtype=tf.int64)\n",
    "    t_ip = tf.cast(t_ip, dtype=tf.float32)\n",
    "    \n",
    "    pred_s_time = time.time()\n",
    "    if predict_rnn is True:\n",
    "        prediction = tf_loaded_model(t_ip, training=False)\n",
    "    else:\n",
    "        indi_embed, prediction, att_weights = tf_loaded_model(t_ip, training=False)\n",
    "        print(indi_embed.shape, prediction.shape, att_weights.shape)\n",
    "    pred_e_time = time.time()\n",
    "    print(\"Time taken to predict tools: {} seconds\".format(pred_e_time - pred_s_time))\n",
    "    prediction_cwts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "    top_k = tf.math.top_k(prediction, k=n_topk_ind, sorted=True)\n",
    "    top_k_wts = tf.math.top_k(prediction_cwts, k=n_topk_ind, sorted=True)\n",
    "\n",
    "    t_ip = t_ip.numpy()[0]\n",
    "    label_pos = np.where(t_ip > 0)[0]\n",
    "    print(t_ip)\n",
    "    print(t_ip.shape, t_ip[label_pos])\n",
    "    i_names = \",\".join([r_dict[str(int(item))] for item in t_ip[label_pos] if item not in [0, \"0\"]])\n",
    "\n",
    "    pred_tools = [r_dict[str(int(item))] for item in top_k.indices.numpy()[0] if item not in [0, \"0\"]]\n",
    "    pred_tools_wts = [r_dict[str(int(item))] for item in top_k_wts.indices.numpy()[0] if item not in [0, \"0\"]]\n",
    "\n",
    "    c_tools = []\n",
    "    if str(f_dict[last_tool_name]) in compatible_tools:\n",
    "        c_tools = [r_dict[str(item)] for item in compatible_tools[str(f_dict[last_tool_name])]]\n",
    "\n",
    "    pred_intersection = list(set(pred_tools).intersection(set(c_tools)))\n",
    "    prd_te_prec = len(pred_intersection) / float(n_topk_ind)\n",
    "\n",
    "    print(\"Tool sequence: {}\".format([r_dict[str(int(item))] for item in t_ip[label_pos]]))\n",
    "    print()\n",
    "    print(\"Compatible true tools: {}, size: {}\".format(c_tools, len(c_tools)))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools: {}\".format(n_topk_ind, pred_tools))\n",
    "    print()\n",
    "    print(\"Predicted precision: {}\".format(prd_te_prec))\n",
    "    print()\n",
    "    print(\"Correctly predicted tools: {}\".format(pred_intersection))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools with weights: {}\".format(n_topk_ind, pred_tools_wts))\n",
    "    print()\n",
    "    if predict_rnn is False:\n",
    "        generated_attention(att_weights, i_names, f_dict, r_dict)\n",
    "\n",
    "\n",
    "def generated_attention(attention_weights, i_names, f_dict, r_dict):\n",
    "    try:\n",
    "        attention_heads = tf.squeeze(attention_weights, 0)\n",
    "    except:\n",
    "        attention_heads = attention_weights\n",
    "    n_heads = attention_heads.shape[1]\n",
    "    i_names = i_names.split(\",\")\n",
    "    in_tokens = i_names\n",
    "    out_tokens = i_names\n",
    "    \n",
    "    mean_att = np.mean(attention_heads, axis=0)\n",
    "    for h, head in enumerate(attention_heads):\n",
    "      plot_attention_head(in_tokens, out_tokens, head)\n",
    "      break\n",
    "\n",
    "\n",
    "def plot_attention_head(in_tokens, out_tokens, attention):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  ax = plt.gca()\n",
    "  cax = ax.matshow(attention[:len(in_tokens), :len(out_tokens)], interpolation='nearest')\n",
    "  ax.set_xlabel(f'Head')\n",
    "\n",
    "  ax.set_xticks(range(len(in_tokens)))\n",
    "  ax.set_xticklabels(in_tokens, rotation=90)\n",
    "\n",
    "  ax.set_yticks(range(len(out_tokens)))\n",
    "  ax.set_yticklabels(out_tokens)\n",
    "  fig.colorbar(cax)\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf440a6b-37c4-4e14-ac55-10c18aff8107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105892, 25) (105892, 2355)\n",
      "../models/rnn/saved_model/40000/tf_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:24:41.004397: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:41.419978: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:41.459101: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:41.617742: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:42.392761: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:42.429210: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.012734: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.157290: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.212651: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.686538: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.719078: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.868844: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:45.913153: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:46.079428: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:46.110609: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:46.340917: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:46.374880: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:46.641464: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:47.064897: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:47.091941: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:47.767455: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:48.001341: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:48.030705: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:48.409485: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:48.436288: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:49.194580: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:49.221850: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-20 16:24:49.264762: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch 1, Tool sequence: ['createInterval', 'samtools_view', 'bedtools_intersectbed', '__MERGE_COLLECTION__', 'samtools_merge']\n",
      "\n",
      "Test batch 1, True tools: ['picard_CollectInsertSizeMetrics', 'picard_artifact_metrics', 'bamFilter', 'bedtools_bamtofastq', 'picard_CollectBaseDistributionByCycle', 'picard_EstimateLibraryComplexity', 'picard_CollectWgsMetrics', 'strelka_germline', 'stringtie', 'picard_DownsampleSam', 'picard_MeanQualityByCycle', 'picard_MarkDuplicates', 'samtools_stats', 'deeptools_bam_coverage', 'samtool_filter2', 'samtools_flagstat', 'picard_CASM', 'picard_CollectGcBiasMetrics', 'pureclip', 'control_freec', 'picard_QualityScoreDistribution', 'samtools_fastx', 'samtools_bedcov', 'freebayes', 'fastqc', 'samtools_rmdup', 'featurecounts']\n",
      "\n",
      "Test batch 1, Predicted top 27 tools: ['samtools_flagstat', 'picard_EstimateLibraryComplexity', 'picard_artifact_metrics', 'samtools_rmdup', 'picard_CollectGcBiasMetrics', 'picard_CollectBaseDistributionByCycle', 'picard_MeanQualityByCycle', 'strelka_germline', 'bedtools_bamtofastq', 'picard_QualityScoreDistribution', 'pureclip', 'deeptools_bam_coverage', 'samtools_bedcov', 'control_freec', 'bamFilter', 'samtools_stats', 'picard_CollectInsertSizeMetrics', 'picard_MarkDuplicates', 'picard_DownsampleSam', 'picard_CollectWgsMetrics', 'picard_CASM', 'samtool_filter2', 'stringtie', 'fastqc', 'freebayes', 'samtools_fastx', 'featurecounts']\n",
      "\n",
      "Test batch 1, Predicted top 27 tools with weights: ['samtools_stats', 'fastqc', 'featurecounts', 'stringtie', 'picard_MarkDuplicates', 'deeptools_bam_coverage', 'freebayes', 'bamFilter', 'samtools_flagstat', 'samtools_fastx', 'bedtools_bamtofastq', 'samtool_filter2', 'samtools_rmdup', 'picard_CollectInsertSizeMetrics', 'pureclip', 'picard_DownsampleSam', 'samtools_bedcov', 'control_freec', 'picard_artifact_metrics', 'strelka_germline', 'picard_QualityScoreDistribution', 'picard_CollectWgsMetrics', 'picard_MeanQualityByCycle', 'picard_CollectBaseDistributionByCycle', 'picard_CollectGcBiasMetrics', 'picard_EstimateLibraryComplexity', 'trinity']\n",
      "\n",
      "Test batch 1, Precision: 1.0\n",
      "\n",
      "Test batch 1, Published precision: 0.48148148148148145\n",
      "\n",
      "Test batch 1, Published precision with weights: 0.4444444444444444\n",
      "\n",
      "Time taken to predict tools: 0.6217763423919678 seconds\n",
      "=========================\n",
      "--------------------------\n",
      "Batch 1 prediction finished ...\n",
      "Test batch 1, Tool sequence: ['__RELABEL_FROM_FILE__', 'fastq_to_fasta_python', 'fasta2tab', 'collapse_dataset', 'Grouping1', 'Filter1', '__FILTER_EMPTY_DATASETS__', 'filter_tabular', 'bg_uniq', 'addValue', 'tab2fasta', 'EMBOSS: revseq82', 'tp_cat', 'fasta2tab', 'trimmer', 'tp_easyjoin_tool', 'cat1', 'rbc_mafft']\n",
      "\n",
      "Test batch 1, True tools: ['newick_display', 'rbc_mafft_add', 'rnaz', 'fasttree', 'iqtree', 'rbc_rnacode', 'gd_raxml', 'tp_cat', 'qiime_pick_otus', 'EMBOSS: tranalign100', 'raxml', 'qiime_assign_taxonomy', 'snp_dists', 'qiime_make_phylogeny', 'rbc_mafft', 'selectsequencesfrommsa', 'interactive_tool_fairdom_send', 'tp_awk_tool', 'clustalw', 'phyml', 'tp_sed_tool', 'prokka', 'EMBOSS: transeq101']\n",
      "\n",
      "Test batch 1, Predicted top 23 tools: ['EMBOSS: tranalign100', 'snp_dists', 'fasttree', 'interactive_tool_fairdom_send', 'EMBOSS: transeq101', 'qiime_make_phylogeny', 'gd_raxml', 'phyml', 'rbc_mafft_add', 'rnaz', 'selectsequencesfrommsa', 'raxml', 'rbc_rnacode', 'qiime_pick_otus', 'clustalw', 'newick_display', 'qiime_assign_taxonomy', 'iqtree', 'rbc_mafft', 'prokka', 'tp_sed_tool', 'tp_awk_tool', 'tp_cat']\n",
      "\n",
      "Test batch 1, Predicted top 23 tools with weights: ['prokka', 'tp_cat', 'tp_awk_tool', 'rbc_mafft', 'tp_sed_tool', 'clustalw', 'fasttree', 'iqtree', 'newick_display', 'snp_dists', 'raxml', 'EMBOSS: transeq101', 'qiime_assign_taxonomy', 'rbc_mafft_add', 'gd_raxml', 'qiime_pick_otus', 'phyml', 'qiime_make_phylogeny', 'selectsequencesfrommsa', 'EMBOSS: tranalign100', 'rnaz', 'rbc_rnacode', 'fasta_merge_files_and_filter_unique_sequences']\n",
      "\n",
      "Test batch 1, Precision: 1.0\n",
      "\n",
      "Test batch 1, Published precision: 0.13043478260869565\n",
      "\n",
      "Test batch 1, Published precision with weights: 0.13043478260869565\n",
      "\n",
      "Time taken to predict tools: 0.6217763423919678 seconds\n",
      "=========================\n",
      "--------------------------\n",
      "Batch 1 prediction finished ...\n",
      "Test batch 1, Tool sequence: ['trimmomatic', 'fastqc', 'Grep1', 'datamash_transpose', 'join1', 'Filter1', 'wc_gnu', 'Remove beginning1', 'Show beginning1', 'Show tail1', 'Convert characters1', 'Cut1', 'Add_a_column1', 'addValue', 'cat1']\n",
      "\n",
      "Test batch 1, True tools: ['cshl_fastq_to_fasta', 'fastq_filter', 'anndata_manipulate', 'humann', 'cshl_fastx_renamer', 'regionalgam_ab_index', 'Convert characters1', 'bedtools_intersectbed', 'CONVERTER_interval_to_bedstrict_0', 'mass_spectrometry_imaging_combine', 'table_compute', 'addValue', 'fastq_paired_end_deinterlacer', 'salmon', 'cutadapt', 'winnowmap', 'tp_cut_tool', 'kraken2', 'quast', 'bwa', 'bismark_bowtie2', 'trinity', 'cardinal_spectra_plots', 'w4mclassfilter', 'filter_by_fasta_ids', 'minimap2', 'cd_hit_est', 'gfastats', 'sort1', 'trimmomatic', 'busco', 'heatmap2', '_ensembl_gtf2gene_list', 'umi_tools_extract', 'tp_replace_in_column', 'cshl_fastx_trimmer', 'uc2otutable', 'stoceps_trend_indic', 'qiime_pick_closed_reference_otus', 'datamash_ops', 'cardinal_classification', 'add_line_to_file', 'tp_sort_header_tool', 'column_remove_by_header', 'random_lines1', '__TAG_FROM_FILE__', 'fasta2tab', 'fastq_to_fasta_python', 'XY_Plot_1', 'checkFormat', '__RELABEL_FROM_FILE__', 'datamash_transpose', 'cardinal_filtering', 'Add_a_column1', 'mothur_phylotype', 'gffcompare', 'stringtie', 'cshl_fastx_barcode_splitter', 'cardinal_combine', 'CONVERTER_fasta_to_tabular', 'merqury', 'volcanoplot', 'seq_filter_by_mapping', 'melt', 'regionalgam_flight_curve', 'unipept', 'tp_find_and_replace', 'rna_starsolo', 'fastq_to_tabular', 'tp_sorted_uniq', 'search_gui', 'fastq_groomer', 'Paste1', 'fastq_paired_end_interlacer', 'Grep1', 'annotatemyids', 'snpfreqplot', 'mothur_unique_seqs', 'trim_galore', 'cshl_fastx_collapser', 'msstatstmt', 'purge_dups', 'ggplot2_point', 'barchart_gnuplot', 'cast', 'regexColumn1', 'hisat2', 'rbc_mafft', 'bedtools_getfastabed', 'targetfinder', 'jbrowse', 'Filter1', 'cd_hit', 'salsa', 'ggplot2_pca', 'porechop', 'pureclip', 'rbc_mirdeep2_mapper', '__FLATTEN__', 'bg_uniq', 'tp_easyjoin_tool', 'rna_star', 'query_tabular', 'multiqc', 'column_order_header_sort', 'join1', 'Grouping1', 'gops_merge_1', 'ChangeCase', 'uniprot', 'bedtools_sortbed', 'minia', 'tabular_to_csv', 'tab2fasta', 'Remove beginning1', 'ggplot2_histogram', 'mergeCols1', 'Cut1', 'join_files_on_column_fuzzy', 'Summary_Statistics1', 'bwa_mem', 'bwa_mem2', 'p_clip_peaks', 'fastqc', 'ctb_chemfp_mol2fps', 'ggplot2_heatmap2', 'proteomics_moff', 'cshl_fastx_clipper', 'uclust2otutable', 'fasta_merge_files_and_filter_unique_sequences', 'ete_homology_classifier', 'ggplot_histogram', 'bowtie2']\n",
      "\n",
      "Test batch 1, Predicted top 133 tools: ['cshl_fastx_renamer', 'tp_replace_in_column', 'XY_Plot_1', 'rna_star', 'fasta2tab', 'cast', 'minia', 'ctb_chemfp_mol2fps', 'ggplot_histogram', 'winnowmap', '_ensembl_gtf2gene_list', 'qiime_pick_closed_reference_otus', 'merqury', 'salsa', 'join1', 'uniprot', 'ggplot2_histogram', 'p_clip_peaks', 'fastq_paired_end_deinterlacer', 'fastq_to_fasta_python', 'unipept', 'fastq_to_tabular', 'Cut1', 'regionalgam_ab_index', 'umi_tools_extract', 'stoceps_trend_indic', 'melt', 'regionalgam_flight_curve', 'purge_dups', 'gops_merge_1', 'cshl_fastq_to_fasta', 'humann', 'cardinal_spectra_plots', 'trim_galore', 'bowtie2', 'porechop', 'column_order_header_sort', 'bedtools_sortbed', 'cardinal_classification', 'targetfinder', 'tab2fasta', 'bwa_mem2', 'fastqc', 'cshl_fastx_clipper', 'mass_spectrometry_imaging_combine', 'cardinal_filtering', 'mothur_phylotype', 'gffcompare', 'cardinal_combine', 'rbc_mirdeep2_mapper', 'gfastats', 'busco', 'volcanoplot', 'snpfreqplot', 'ggplot2_pca', 'tp_easyjoin_tool', 'uc2otutable', 'search_gui', 'uclust2otutable', 'rna_starsolo', 'ete_homology_classifier', 'bedtools_intersectbed', 'heatmap2', 'msstatstmt', 'random_lines1', 'ggplot2_heatmap2', 'proteomics_moff', 'query_tabular', 'tp_sort_header_tool', 'fastq_paired_end_interlacer', 'annotatemyids', 'cd_hit', 'pureclip', 'w4mclassfilter', 'CONVERTER_fasta_to_tabular', '__TAG_FROM_FILE__', 'sort1', 'cshl_fastx_collapser', 'tabular_to_csv', 'anndata_manipulate', 'CONVERTER_interval_to_bedstrict_0', 'quast', 'bismark_bowtie2', 'datamash_transpose', 'fastq_filter', 'Grouping1', 'cshl_fastx_trimmer', 'hisat2', 'join_files_on_column_fuzzy', 'tp_sorted_uniq', 'ggplot2_point', 'kraken2', 'rbc_mafft', 'checkFormat', 'trimmomatic', 'cshl_fastx_barcode_splitter', 'barchart_gnuplot', 'ChangeCase', 'seq_filter_by_mapping', 'Remove beginning1', 'mothur_unique_seqs', 'regexColumn1', '__RELABEL_FROM_FILE__', 'cutadapt', 'Convert characters1', 'bwa', 'Paste1', 'bg_uniq', 'add_line_to_file', 'column_remove_by_header', 'trinity', 'cd_hit_est', 'datamash_ops', 'filter_by_fasta_ids', 'Add_a_column1', '__FLATTEN__', 'Summary_Statistics1', 'mergeCols1', 'multiqc', 'stringtie', 'Grep1', 'tp_find_and_replace', 'minimap2', 'fastq_groomer', 'Filter1', 'bedtools_getfastabed', 'fasta_merge_files_and_filter_unique_sequences', 'tp_cut_tool', 'jbrowse', 'bwa_mem', 'salmon', 'table_compute', 'addValue']\n",
      "\n",
      "Test batch 1, Predicted top 133 tools with weights: ['Add_a_column1', 'tp_find_and_replace', 'bwa_mem', 'fastqc', 'datamash_ops', 'gops_merge_1', 'bowtie2', 'rna_star', 'hisat2', 'trimmomatic', 'kraken2', 'cutadapt', 'fastq_to_fasta_python', 'multiqc', 'minimap2', 'trim_galore', 'stringtie', 'fasta2tab', 'fastq_groomer', 'porechop', 'tab2fasta', 'tp_easyjoin_tool', 'table_compute', 'bedtools_intersectbed', 'tp_sort_header_tool', 'ggplot2_heatmap2', 'quast', 'busco', 'datamash_transpose', 'salmon', 'volcanoplot', 'rbc_mafft', 'bwa', 'bwa_mem2', 'mothur_unique_seqs', 'addValue', 'annotatemyids', 'jbrowse', 'tp_replace_in_column', 'fastq_paired_end_interlacer', 'cshl_fastx_collapser', 'bedtools_sortbed', 'cshl_fastq_to_fasta', 'bedtools_getfastabed', 'anndata_manipulate', 'cshl_fastx_trimmer', 'cd_hit', 'XY_Plot_1', 'fasta_merge_files_and_filter_unique_sequences', 'rbc_mirdeep2_mapper', 'humann', 'bg_uniq', 'trinity', 'fastq_filter', 'fastq_to_tabular', 'regexColumn1', 'filter_by_fasta_ids', 'mergeCols1', 'ggplot2_point', 'snpfreqplot', 'cshl_fastx_barcode_splitter', 'umi_tools_extract', 'search_gui', 'tp_sorted_uniq', 'purge_dups', 'ggplot2_pca', 'bismark_bowtie2', 'add_line_to_file', 'cshl_fastx_clipper', 'unipept', 'column_remove_by_header', 'salsa', 'uniprot', 'minia', 'cshl_fastx_renamer', 'merqury', 'rna_starsolo', 'pureclip', 'cardinal_spectra_plots', 'gffcompare', 'fastq_paired_end_deinterlacer', '_ensembl_gtf2gene_list', 'seq_filter_by_mapping', 'msstatstmt', 'join_files_on_column_fuzzy', 'gfastats', 'ctb_chemfp_mol2fps', 'ggplot2_histogram', 'targetfinder', 'cardinal_combine', 'qiime_pick_closed_reference_otus', 'winnowmap', 'checkFormat', 'regionalgam_ab_index', 'cast', 'regionalgam_flight_curve', 'stoceps_trend_indic', 'mass_spectrometry_imaging_combine', 'ete_homology_classifier', 'melt', 'tp_tail_tool', 'tp_replace_in_line', 'featurecounts', 'tp_cat', 'tp_sed_tool', 'deseq2', 'fasta-stats', 'filter_tabular', 'tp_grep_tool', 'tp_multijoin_tool', 'taxonomy_krona_chart', 'nanoplot', 'spades', 'medaka_consensus_pipeline', 'regex1', 'freebayes', 'unicycler', 'tp_split_on_column', 'bg_column_arrange_by_header', 'lofreq_call', 'sam_merge2', 'split_file_to_collection', 'seqtk_subseq', 'circos', 'fasta_filter_by_length', 'picard_SortSam', 'flye', 'fastp', 'samtools_stats', 'bamFilter', 'meryl', 'chipseeker', 'cardinal_mz_images']\n",
      "\n",
      "Test batch 1, Precision: 1.0\n",
      "\n",
      "Test batch 1, Published precision: 0.14285714285714285\n",
      "\n",
      "Test batch 1, Published precision with weights: 0.10526315789473684\n",
      "\n",
      "Time taken to predict tools: 0.6217763423919678 seconds\n",
      "=========================\n",
      "--------------------------\n",
      "Batch 1 prediction finished ...\n",
      "Test batch 1, Tool sequence: ['trim_galore', 'bowtie2', 'macs2_callpeak', 'bedtools_intersectbed', 'sort1', 'tp_head_tool', 'Remove beginning1', 'chipseeker', 'samtools_rmdup', 'diffbind', 'Filter1', 'Cut1']\n",
      "\n",
      "Test batch 1, True tools: ['tp_tail_tool', 'bedtools_genomecoveragebed', 'trimmer', 'Convert characters1', 'bedtools_intersectbed', 'table_compute', 'addValue', 'clusterprofiler_bitr', 'picard_FilterSamReads', 'fasterq_dump', 'iReport', 'tp_cut_tool', 'Krona', 'gtf_filter_by_attribute_values_list', 'tp_split_on_column', 'bg_column_arrange_by_header', 'openbabel_remIons', 'ncbi_blastdbcmd_wrapper', 'ggplot_point', 'macs2_callpeak', 'w4mclassfilter', 'filter_by_fasta_ids', 'sort1', 'venn_list', 'interactive_tool_simtext_app', 'msstats', 'tp_cat', 'get_flanks1', 'ip_projective_transformation_points', 'bedtools_intersectbed_bam', 'umi_tools_extract', 'tp_replace_in_column', 'music_construct_eset', 'CONVERTER_interval_to_bed_0', 'regex1', 'bcftools_consensus', 'Kraken2Tax', 'addName', 'datamash_ops', 'MassCalculator', 'add_line_to_file', 'tp_sort_header_tool', 'cat_multiple', 'deeptools_compute_matrix', 'random_lines1', 'goenrichment', 'fgsea', 'Extract genomic DNA 1', 'collapse_dataset', 'param_value_from_file', 'tp_head_tool', '__TAG_FROM_FILE__', 'scanpy_read_10x', 'pathview', '__BUILD_LIST__', 'XY_Plot_1', 'checkFormat', 'tp_grep_tool', 'gtftobed12', '__RELABEL_FROM_FILE__', 'datamash_transpose', 'cardinal_filtering', 'dexseq_count', 'wig_to_bigWig', 'ont_fast5_api_fast5_subset', 'seqtk_subseq', 'Add_a_column1', 'wc_gnu', 'gops_concat_1', 'volcanoplot', 'Count1', 'unipept', 'gops_intersect_1', 'ncbi_acc_download', 'tp_find_and_replace', 'rna_starsolo', 'xarray_mapplot', 'tp_sorted_uniq', 'pygenomeTracks', 'heinz_bum', 'interactions', 'Paste1', 'plotly_ml_performance_plots', 'Grep1', 'annotatemyids', 'CONVERTER_bed_to_gff_0', 'stacks_denovomap', 'secure_hash_message_digest', 'goseq', 'mass_spectrometry_imaging_ion_images', 'hgv_david', 'combine_metaphlan2_humann2', 'crossmap_bed', 'gops_coverage_1', 'ggplot2_point', 'get_feature_info', 'heinz_scoring', 'limma_voom', 'cat1', 'barchart_gnuplot', 'sklearn_ensemble', 'fa-extract-sequence', 'regexColumn1', 'ggplot2_heatmap', 'bedtools_getfastabed', 'get_sequences', 'biotranslator', 'annotateMyIDs', 'stringtie_merge', 'Show beginning1', 'gops_subtract_1', 'cshl_find_and_replace', 'taxonomy_krona_chart', 'egsea', 'Filter1', 'export2graphlan', 'scatterplot_rpy', 'ggplot2_pca', 'tp_replace_in_line', 'deseq2', 'tp_multijoin_tool', 'charts', 'samtools_view', 'krona-text', 'Show tail1', '__FLATTEN__', 'dropletutils_read_10x', 'tp_awk_tool', 'bedtools_slopbed', 'bg_uniq', 'tp_easyjoin_tool', 'subtract_query1', 'rna_star', '__FILTER_FROM_FILE__', 'query_tabular', 'join1', 'Grouping1', 'tp_sed_tool', 'histogram_rpy', 'comp1', 'ChangeCase', 'regex_replace', 'bedtools_sortbed', 'tab2fasta', 'bedtools_mergebed', 'Remove beginning1', 'gops_join_1', 'stacks_populations', 'mergeCols1', 'cshl_word_list_grep', 'join_files_on_column_fuzzy', 'Summary_Statistics1', 'diff', 'tp_uniq_tool', 'length_and_gc_content', 'seq_filter_by_id', 'circos', 'ggplot2_heatmap2', 'featurecounts', 'collection_column_join', 'split_file_to_collection', 'tabular_to_fastq', 'ggplot_histogram']\n",
      "\n",
      "Test batch 1, Predicted top 163 tools: ['Convert characters1', 'bedtools_intersectbed', 'table_compute', 'addValue', 'sort1', 'tp_cat', 'tp_replace_in_column', 'tp_sort_header_tool', 'random_lines1', 'goenrichment', 'Extract genomic DNA 1', 'XY_Plot_1', 'datamash_transpose', 'wig_to_bigWig', 'gops_intersect_1', 'tp_find_and_replace', 'Paste1', 'hgv_david', 'ggplot2_point', 'join1', 'comp1', 'ChangeCase', 'bedtools_sortbed', 'Remove beginning1', 'Summary_Statistics1', 'ggplot2_heatmap2', 'tp_tail_tool', 'tp_cut_tool', 'pathview', 'Add_a_column1', 'ncbi_acc_download', 'tp_sorted_uniq', 'pygenomeTracks', 'cat1', 'get_sequences', 'gops_subtract_1', 'bedtools_mergebed', 'stacks_populations', 'trimmer', 'fgsea', 'dexseq_count', 'gops_concat_1', 'plotly_ml_performance_plots', 'goseq', 'crossmap_bed', 'gops_coverage_1', 'tp_easyjoin_tool', 'histogram_rpy', 'join_files_on_column_fuzzy', 'ggplot_histogram', 'datamash_ops', 'cat_multiple', 'heinz_bum', 'stacks_denovomap', 'heinz_scoring', 'annotateMyIDs', 'egsea', 'bedtools_slopbed', 'subtract_query1', 'bg_column_arrange_by_header', 'deeptools_compute_matrix', 'tp_head_tool', 'bedtools_getfastabed', 'tp_replace_in_line', 'diff', 'bedtools_genomecoveragebed', 'ip_projective_transformation_points', 'bedtools_intersectbed_bam', 'param_value_from_file', '__TAG_FROM_FILE__', 'combine_metaphlan2_humann2', 'limma_voom', 'regexColumn1', 'regex_replace', 'circos', 'Kraken2Tax', 'sklearn_ensemble', 'deseq2', 'cshl_word_list_grep', 'msstats', 'ont_fast5_api_fast5_subset', 'mass_spectrometry_imaging_ion_images', 'venn_list', 'openbabel_remIons', 'ggplot_point', 'macs2_callpeak', 'interactive_tool_simtext_app', 'music_construct_eset', 'xarray_mapplot', 'interactions', 'get_feature_info', 'fa-extract-sequence', 'length_and_gc_content', 'clusterprofiler_bitr', 'Krona', 'ncbi_blastdbcmd_wrapper', 'MassCalculator', 'unipept', 'annotatemyids', 'cshl_find_and_replace', 'bg_uniq', 'picard_FilterSamReads', 'barchart_gnuplot', 'gops_join_1', 'fasterq_dump', 'get_flanks1', 'volcanoplot', 'secure_hash_message_digest', 'export2graphlan', 'tp_uniq_tool', 'iReport', 'CONVERTER_bed_to_gff_0', 'ggplot2_pca', 'dropletutils_read_10x', 'tp_awk_tool', 'tp_split_on_column', 'split_file_to_collection', 'gtf_filter_by_attribute_values_list', 'umi_tools_extract', 'addName', 'collection_column_join', 'Show tail1', 'bcftools_consensus', 'Show beginning1', 'Grep1', 'ggplot2_heatmap', 'cardinal_filtering', 'biotranslator', 'rna_star', 'tp_sed_tool', 'samtools_view', 'tab2fasta', 'scanpy_read_10x', 'Grouping1', 'seq_filter_by_id', 'collapse_dataset', 'tabular_to_fastq', 'seqtk_subseq', 'wc_gnu', 'tp_multijoin_tool', 'krona-text', 'mergeCols1', '__FILTER_FROM_FILE__', '__FLATTEN__', 'scatterplot_rpy', 'rna_starsolo', 'gtftobed12', '__RELABEL_FROM_FILE__', '__BUILD_LIST__', 'stringtie_merge', 'w4mclassfilter', 'add_line_to_file', 'taxonomy_krona_chart', 'filter_by_fasta_ids', 'checkFormat', 'CONVERTER_interval_to_bed_0', 'featurecounts', 'Count1', 'tp_grep_tool', 'charts', 'Filter1', 'regex1', 'query_tabular']\n",
      "\n",
      "Test batch 1, Predicted top 163 tools with weights: ['Add_a_column1', 'tp_find_and_replace', 'samtools_view', 'tp_replace_in_line', 'bcftools_consensus', 'bedtools_genomecoveragebed', 'datamash_ops', 'gops_concat_1', 'gops_subtract_1', 'featurecounts', 'rna_star', 'fasterq_dump', 'deseq2', 'tp_cat', 'deeptools_compute_matrix', 'tab2fasta', 'tp_easyjoin_tool', 'table_compute', 'bedtools_intersectbed', 'tp_sort_header_tool', 'ggplot2_heatmap2', 'collapse_dataset', 'datamash_transpose', 'volcanoplot', 'macs2_callpeak', 'tp_awk_tool', 'taxonomy_krona_chart', 'tp_sed_tool', 'circos', 'collection_column_join', 'tp_grep_tool', 'gops_intersect_1', 'goseq', 'addValue', 'annotatemyids', 'addName', 'tp_replace_in_column', 'limma_voom', 'Kraken2Tax', 'bedtools_sortbed', 'seqtk_subseq', 'bedtools_getfastabed', 'bedtools_mergebed', 'tp_tail_tool', 'XY_Plot_1', 'split_file_to_collection', 'bg_uniq', 'regexColumn1', 'seq_filter_by_id', 'filter_by_fasta_ids', 'mergeCols1', 'ggplot2_point', 'gtftobed12', 'dexseq_count', 'tp_multijoin_tool', 'ncbi_acc_download', 'combine_metaphlan2_humann2', 'pathview', 'umi_tools_extract', 'fgsea', 'tp_sorted_uniq', 'krona-text', 'regex1', 'ggplot2_pca', 'tabular_to_fastq', 'tp_head_tool', 'venn_list', 'goenrichment', 'add_line_to_file', 'stringtie_merge', 'tp_split_on_column', 'Extract genomic DNA 1', 'picard_FilterSamReads', 'export2graphlan', 'unipept', 'ggplot2_heatmap', 'bg_column_arrange_by_header', 'ncbi_blastdbcmd_wrapper', 'msstats', 'get_flanks1', 'rna_starsolo', 'egsea', 'length_and_gc_content', 'scanpy_read_10x', 'tp_uniq_tool', 'scatterplot_rpy', 'bedtools_slopbed', 'join_files_on_column_fuzzy', 'dropletutils_read_10x', 'pygenomeTracks', 'subtract_query1', 'clusterprofiler_bitr', 'charts', 'xarray_mapplot', 'music_construct_eset', 'ip_projective_transformation_points', 'diff', 'get_feature_info', 'sklearn_ensemble', 'get_sequences', 'crossmap_bed', 'checkFormat', 'plotly_ml_performance_plots', 'heinz_scoring', 'ont_fast5_api_fast5_subset', 'openbabel_remIons', 'MassCalculator', 'bwa_mem', 'jbrowse', 'bowtie2', 'minimap2', 'kraken2', 'fasta_filter_by_length', 'fastqc', 'bedtools_subtractbed', 'chipseeker', 'fastq_groomer', 'edger', 'fasta-stats', 'column_remove_by_header', 'filter_tabular', 'multiqc', 'anndata_manipulate', 'htseq_count', 'busco', 'fasta_merge_files_and_filter_unique_sequences', 'bedtools_maskfastabed', 'ncbi_blastn_wrapper', 'sam_merge2', 'deeptools_plot_heatmap', 'deg_annotate', 'metabat2', 'qualimap_rnaseq', 'pilon', 'nanoplot', 'quast', 'samtools_slice_bam', 'humann2_renorm_table', 'fastq_filter', 'datamash_reverse', 'mothur_chimera_vsearch', 'snpEff', 'bwa', 'eggnog_mapper', 'homer_annotatePeaks', 'je_demultiplex', 'cardinal_spectra_plots', 'deeptools_plot_profile', 'bamleftalign', 'freebayes', 'chipeakanno_annopeaks', 'clustalw', 'compress_file', 'datasets_download_genome', 'bedtools_genomecoveragebed_bedgraph', 'cshl_fastx_collapser', 'meme_chip', 'hisat2', 'bcftools_norm', 'cardinal_mz_images', 'hypo', 'vigiechiro_idcorrect_2ndlayer', 'macs2_bdgdiff']\n",
      "\n",
      "Test batch 1, Precision: 1.0\n",
      "\n",
      "Test batch 1, Published precision: 0.3006134969325153\n",
      "\n",
      "Test batch 1, Published precision with weights: 0.2147239263803681\n",
      "\n",
      "Time taken to predict tools: 0.6217763423919678 seconds\n",
      "=========================\n",
      "--------------------------\n",
      "Batch 1 prediction finished ...\n",
      "Test batch 1, Tool sequence: ['preproc', 'fasplit', 'viennarna_rnafold', 'collapse_dataset', 'structure_to_gspan', 'nspdk_sparse', 'NSPDK_candidateClust']\n",
      "\n",
      "Test batch 1, True tools: ['tp_cat', 'preMloc']\n",
      "\n",
      "Test batch 1, Predicted top 2 tools: ['tp_cat', 'preMloc']\n",
      "\n",
      "Test batch 1, Predicted top 2 tools with weights: ['tp_cat', 'preMloc']\n",
      "\n",
      "Test batch 1, Precision: 1.0\n",
      "\n",
      "Test batch 1, Published precision: 0.5\n",
      "\n",
      "Test batch 1, Published precision with weights: 0.5\n",
      "\n",
      "Time taken to predict tools: 0.6217763423919678 seconds\n",
      "=========================\n",
      "--------------------------\n",
      "Batch 1 prediction finished ...\n",
      "Time taken to predict tools: 2.9432926177978516 seconds\n",
      "[1596.  550.  157. 1484.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.] [0 1 2 3]\n",
      "0, Low: test tool sequence: ['TrimPrimer', 'Flash', 'Btrim64', 'uparse']\n",
      "\n",
      "0,Low: True labels: ['rarefaction', 'pynast', '16Sclassifier', '16Saligner']\n",
      "\n",
      "0,Low: Predicted labels: ['16Saligner', '16Sclassifier', 'rarefaction', 'pynast'], Precision: 1.0\n",
      "-----------------\n",
      "\n",
      "Batch Precision@2: 1.0\n",
      "Batch Published Precision@2: 0.3110773807759671\n",
      "Batch Trained model loading time: 16.111982822418213 seconds\n",
      "Batch average seq pred time: 0.6217763423919678 seconds\n",
      "Batch total model loading and pred time: 16.73375916481018 seconds\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Predicting for individual sequences...\n",
      "\n",
      "Predicting for individual tools or sequences\n",
      "Time taken to predict tools: 0.013383150100708008 seconds\n",
      "[2335.  358.  484. 1009. 2043.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.]\n",
      "(25,) [2335.  358.  484. 1009. 2043.]\n",
      "Tool sequence: ['bowtie2', 'hicexplorer_hicbuildmatrix', 'hicexplorer_chicqualitycontrol', 'hicexplorer_chicviewpointbackgroundmodel', 'hicexplorer_chicviewpoint']\n",
      "\n",
      "Compatible true tools: ['hicexplorer_chicsignificantinteractions', 'hicexplorer_chicaggregatestatistic'], size: 2\n",
      "\n",
      "Predicted top 20 tools: ['hicexplorer_chicsignificantinteractions', 'hicexplorer_chicaggregatestatistic', 'hicexplorer_chicdifferentialtest', 'heinz', 'hicexplorer_chicviewpoint', 'react_cal_pipeline', 'taxoptimizer', 'edu.tamu.cpt.gff3.lipoP_to_gff3', 'gffcompare_to_bed', 'extract', 'flair_collapse', 'edu.tamu.cpt2.phage.intron_detection', 'fasta_merge_files_and_filter_unique_sequences', 'mothur_classify_otu', 'methylkit', 'ChooseTag', 'mothur_remove_rare', 'nanocompore_db', 'mass_spectrometry_imaging_qc', 'OpenSwathAssayGenerator']\n",
      "\n",
      "Predicted precision: 0.1\n",
      "\n",
      "Correctly predicted tools: ['hicexplorer_chicaggregatestatistic', 'hicexplorer_chicsignificantinteractions']\n",
      "\n",
      "Predicted top 20 tools with weights: ['hicexplorer_chicaggregatestatistic', 'hicexplorer_chicsignificantinteractions', 'fasta_merge_files_and_filter_unique_sequences', 'gffcompare_to_bed', 'tp_cat', 'heinz', 'hicexplorer_chicviewpoint', 'pretext_map', 'FileInfo', 'ncbi_blastn_wrapper', 'deg_annotate', 'busco', 'react_cal_pipeline', 'mothur_remove_rare', 'qiime_pick_open_reference_otus', 'bedtools_intersectbed', 'fastq_groomer', 'meme_chip', 'fastq_filter', 'qiime_count_seqs']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8684f8c-d72d-4fc7-8624-d42666a41d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f70d1a-4f98-421d-abb4-b53a01bd4d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7156a5a-e353-4c21-9141-26a5e5995ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f474443-0a97-4f2a-98d0-6c943eb77821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f478ba-b227-4088-8d0d-f205c729c503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
